{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae1c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\python310\\lib\\site-packages (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "# installing missing libraries\n",
    "!pip install pymysql\n",
    "\n",
    "# importing libraries\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78ca0e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9188/3488808967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# download edinburgh_bikes from server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'SELECT * FROM edinburgh_bikes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mysql+pymysql://data-student:u9AB6hWGsNkNcRDm@data.engeto.com:3306/data_academy_04_2022\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# save the table as dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_bikes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# download edinburgh_bikes from server \n",
    "query = 'SELECT * FROM edinburgh_bikes'\n",
    "engine = create_engine(\"mysql+pymysql://data-student:u9AB6hWGsNkNcRDm@data.engeto.com:3306/data_academy_04_2022\")\n",
    "# save the table as dataframe\n",
    "df_bikes = pd.read_sql(sql=query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac9e739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_weather' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9188/207036966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_weather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_weather' is not defined"
     ]
    }
   ],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d585830",
   "metadata": {},
   "source": [
    "# Detailed examination of the list of station names managed to identify likely misspellings in the names of the stations:\n",
    "\n",
    "1. Bruntsfield **L**inks X Bruntsfield **l**inks\n",
    "2. Picady Place | Pica**r**dy Place\n",
    "3. Waitrose Comely Bank | Waitrose**,** Comely Bank\n",
    "\n",
    "not necesserary a typo, but might be better to unify since they have close spatial relationships:\n",
    "\n",
    "4. Kings Building 2 | Kings Building 3 | Kings Building**s** 1 | Kings Building**s** 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42b915",
   "metadata": {},
   "source": [
    "### add 1. Bruntsfield **L**inks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0442120",
   "metadata": {},
   "outputs": [],
   "source": [
    "BruntsfieldLinks_used = df_bikes[df_bikes['start_station_name'] == 'Bruntsfield Links'].shape[0]\n",
    "print(f'Station Bruntsfield Links was used {BruntsfieldLinks_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Bruntsfield Links'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f1c12",
   "metadata": {},
   "source": [
    "### add 1. Bruntsfield **l**inks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bruntsfieldlinks_used = df_bikes[df_bikes['start_station_name'] == 'Bruntsfield links'].shape[0]\n",
    "print(f'Station Bruntsfield links was used {Bruntsfieldlinks_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Bruntsfield links'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd175632",
   "metadata": {},
   "source": [
    "If we compare these two station names, we will see that they do not have the same name, description, or coordinates. From this we can conclude that it is not a typo in the database. But what is likely is that the original station was replaced with a new one. The analysis of active and inactive stations will take care of solving this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aebcb4",
   "metadata": {},
   "source": [
    "### add 2. Picady Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2455d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PicadyPlace_used = df_bikes[df_bikes['start_station_name'] == 'Picady Place'].shape[0]\n",
    "print(f'Station Picady Place was used {PicadyPlace_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Picady Place'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edfcbe",
   "metadata": {},
   "source": [
    "### add2. Pica**r**dy Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38003811",
   "metadata": {},
   "outputs": [],
   "source": [
    "PicardyPlace_used = df_bikes[df_bikes['start_station_name'] == 'Picardy Place'].shape[0]\n",
    "print(f'Station Picardy Place was used {PicardyPlace_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Picardy Place'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05447b67",
   "metadata": {},
   "source": [
    "If we compare these two station names, we will see that they have the same description and coordinates. In addition, the first mentioned station was used only once. From this we can conclude that it is a typo in the database. In this case, we are allowed to correct the error by overwriting the correct name of the station:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314dbb4",
   "metadata": {},
   "source": [
    "Overwriting the correct name of the station Picardy Place: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bikes.loc[df_bikes['start_station_name'] == 'Picady Place', 'start_station_name'] = 'Picardy Place'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e9fbe0",
   "metadata": {},
   "source": [
    "### add 3. Waitrose Comely Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WaitroseComelyBank_used = df_bikes[df_bikes['start_station_name'] == 'Waitrose Comely Bank'].shape[0]\n",
    "print(f'Station Waitrose Comely Bank was used {WaitroseComelyBank_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Waitrose Comely Bank'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe0eae",
   "metadata": {},
   "source": [
    "### add3. Waitrose**,** Comely Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Waitrose_ComelyBank_used = df_bikes[df_bikes['start_station_name'] == 'Waitrose, Comely Bank'].shape[0]\n",
    "print(f'Station Waitrose, Comely Bank was used {Waitrose_ComelyBank_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Waitrose, Comely Bank'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72af2a6",
   "metadata": {},
   "source": [
    "If we compare these two station names, we will see that they do not have the same name, description, or coordinates. From this we can conclude that it is not a typo in the database. But what is likely is that the original station was replaced with a new one. The analysis of active and inactive stations will take care of solving this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12908e4",
   "metadata": {},
   "source": [
    "### add4. Waitrose Kings Buildings 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9c9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KingsBuildings1_used = df_bikes[df_bikes['start_station_name'] == 'Kings Buildings 1'].shape[0]b\n",
    "print(f'Station Kings Buildings 1 was used {KingsBuildings1_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Kings Buildings 1'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d4097",
   "metadata": {},
   "source": [
    "### add4. Waitrose Kings Building 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KingsBuilding2_used = df_bikes[df_bikes['start_station_name'] == 'Kings Building 2'].shape[0]\n",
    "print(f'Station Kings Building 2 was used {KingsBuilding2_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Kings Building 2'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21750647",
   "metadata": {},
   "source": [
    "### add4. Waitrose Kings Building 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d66c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "KingsBuilding3_used = df_bikes[df_bikes['start_station_name'] == 'Kings Building 3'].shape[0]\n",
    "print(f'Station Kings Building 3 was used {KingsBuilding3_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Kings Building 3'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235b921",
   "metadata": {},
   "source": [
    "### add4. Waitrose Kings Buildings 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a774b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KingsBuildings4_used = df_bikes[df_bikes['start_station_name'] == 'Kings Buildings 4'].shape[0]\n",
    "print(f'Station Kings Buildings 4 was used {KingsBuildings4_used} times.')\n",
    "\n",
    "df_bikes[df_bikes['start_station_name'] == 'Kings Buildings 4'][\n",
    "    ['ended_at', 'start_station_name', 'start_station_description', \n",
    "     'start_station_latitude', 'start_station_longitude']].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b325c35",
   "metadata": {},
   "source": [
    "The usage, description and coordinate of those stations are so different that we rather keep those stations untouched ;-)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd0e38",
   "metadata": {},
   "source": [
    "# Final writing of a clean dataframe into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ca04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bikes.to_csv('edinburgh_bikes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2f607",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Modifying `edinburgh_weather` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download edinburgh_weather from server \n",
    "query = 'SELECT * FROM edinburgh_weather'\n",
    "engine = create_engine(\"mysql+pymysql://data-student:u9AB6hWGsNkNcRDm@data.engeto.com:3306/data_academy_04_2022\")\n",
    "# save the table as dataframe\n",
    "df_weather = pd.read_sql(sql=query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying `wind` column\n",
    "df_weather['wind-dir'] = df_weather['wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42143132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-arranging column to meet the eye :-)\n",
    "cols = df_weather.columns.tolist()\n",
    "cols = cols[10:11] + cols[:10] + cols[11:12]\n",
    "cols2 = cols[:5] + cols[-1:] + cols[5:-1]\n",
    "df_weather = df_weather[cols2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7123dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping values in columns and transforming into int or float format\n",
    "df_weather['temp'] = df_weather['temp'].str.replace('°c', '').astype('int')\n",
    "df_weather['feels'] = df_weather['feels'].str.replace('°c', '').astype('int')\n",
    "\n",
    "df_weather['wind'] = df_weather['wind'].str.strip('km/hfromSWEN ').astype('int')\n",
    "df_weather['wind-dir'] = df_weather['wind-dir'].str.strip('km/hfrom1234567890 ').astype('str')\n",
    "df_weather['gust'] = df_weather['gust'].str.replace('km/h', '').astype('int')\n",
    "\n",
    "df_weather['rain'] = df_weather['rain'].str.replace('mm', '').astype('float')\n",
    "df_weather['humidity'] = df_weather['humidity'].str.replace('%', '').astype('int')\n",
    "df_weather['cloud'] = df_weather['cloud'].str.replace('%', '').astype('int')\n",
    "\n",
    "df_weather['pressure'] = df_weather['pressure'].str.replace('mb', '').astype('int')\n",
    "\n",
    "\n",
    "# renaming column names\n",
    "df_weather = df_weather.rename(columns={\n",
    "    \"temp\": \"temp[°C]\", \n",
    "    \"feels\": \"feels[°C]\",\n",
    "    \"wind\": \"wind[km/h]\",\n",
    "    \"gust\": \"gust[km/h]\",\n",
    "    \"rain\": \"rain[mm]\",\n",
    "    \"humidity\": \"humidity[%]\",\n",
    "    \"cloud\": \"cloud[%]\",\n",
    "    \"pressure\": \"pressure[mb]\",\n",
    "    \"vis\": \"visibility\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e10a4",
   "metadata": {},
   "source": [
    "# Final writing of a clean dataframe into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74344c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_csv('edinburgh_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a1cc857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>temp[°C]</th>\n",
       "      <th>feels[°C]</th>\n",
       "      <th>wind[km/h]</th>\n",
       "      <th>wind-dir</th>\n",
       "      <th>gust[km/h]</th>\n",
       "      <th>rain[mm]</th>\n",
       "      <th>humidity[%]</th>\n",
       "      <th>cloud[%]</th>\n",
       "      <th>pressure[mb]</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>S</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>1020</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>SSW</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>96</td>\n",
       "      <td>1020</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>06:00</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>SSW</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>1020</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>SSW</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>1021</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12:00</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>SSW</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>1021</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>6331</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>09:00</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>SSE</td>\n",
       "      <td>33</td>\n",
       "      <td>0.4</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>993</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>6332</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>12:00</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>SSE</td>\n",
       "      <td>37</td>\n",
       "      <td>0.4</td>\n",
       "      <td>88</td>\n",
       "      <td>94</td>\n",
       "      <td>987</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>6333</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>15:00</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>SW</td>\n",
       "      <td>55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>989</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>6334</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>18:00</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>WSW</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>994</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>6335</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>21:00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>SW</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>997</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6336 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date   time  temp[°C]  feels[°C]  wind[km/h] wind-dir  \\\n",
       "0              0  2018-09-01  00:00        11         11           9        S   \n",
       "1              1  2018-09-01  03:00        13         12          11      SSW   \n",
       "2              2  2018-09-01  06:00        14         13          11      SSW   \n",
       "3              3  2018-09-01  09:00        14         13          14      SSW   \n",
       "4              4  2018-09-01  12:00        16         16          15      SSW   \n",
       "...          ...         ...    ...       ...        ...         ...      ...   \n",
       "6331        6331  2020-10-31  09:00        14         12          21      SSE   \n",
       "6332        6332  2020-10-31  12:00        14         12          24      SSE   \n",
       "6333        6333  2020-10-31  15:00        10          6          42       SW   \n",
       "6334        6334  2020-10-31  18:00         9          5          38      WSW   \n",
       "6335        6335  2020-10-31  21:00         8          4          36       SW   \n",
       "\n",
       "      gust[km/h]  rain[mm]  humidity[%]  cloud[%]  pressure[mb] visibility  \n",
       "0             19       0.0           79        13          1020  Excellent  \n",
       "1             19       0.0           76        96          1020  Excellent  \n",
       "2             19       0.0           84       100          1020  Excellent  \n",
       "3             23       0.1           88        78          1021  Excellent  \n",
       "4             22       0.0           87        87          1021  Excellent  \n",
       "...          ...       ...          ...       ...           ...        ...  \n",
       "6331          33       0.4           86       100           993       Poor  \n",
       "6332          37       0.4           88        94           987       Poor  \n",
       "6333          55       0.5           75       100           989  Excellent  \n",
       "6334          54       0.0           76        79           994  Excellent  \n",
       "6335          49       0.1           74        79           997  Excellent  \n",
       "\n",
       "[6336 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = pd.read_csv('edinburgh_weather.csv')\n",
    "df_weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
